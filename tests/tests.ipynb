{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0 import depedent libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# import package(from parent directory)\n",
    "parent_dir = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "sys.path.insert(0, parent_dir)\n",
    "from out_of_sample_test import generate_random_list,mfcf_test\n",
    "from set_up import *\n",
    "from markowirtz_networks import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 out of sample test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Different expected return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting parameter\n",
    "training_window_list = [30]\n",
    "testing_window_list = [21]\n",
    "method_list = ['mean','std','ema','std_o','capm',]\n",
    "num_iter=100\n",
    "sample_size = 20\n",
    "max_clique_size_list = [2,3,5,7,10,15,20]#,50]\n",
    "#iteration_range_mfcf = np.arange(-0.05,0.05,0.001) # for small scale\n",
    "iteration_range_mfcf = np.arange(-1,3,0.05) # for large scale\n",
    "save_result = False\n",
    "# generate dataset\n",
    "return_rate_matrix,model_input = generate_nasdaq() \n",
    "in_sample_return_matrix_list, out_sample_return_matrix_list, random_date_list = generate_random_list(return_rate_matrix, model_input, training_window_list, testing_window_list, num_iter=num_iter,sample_size=sample_size)\n",
    "ct_control = {\n",
    "'max_clique_size': 2,\n",
    "'min_clique_size': 1,\n",
    "'threshold': 0.00,\n",
    "'coordination_num':np.inf,\n",
    "'drop_sep': False\n",
    "}\n",
    "\n",
    "for method in method_list:\n",
    "    for testing_window in testing_window_list:\n",
    "        sum_var = [] # result list of variance\n",
    "        sum_ret = [] # result list of return\n",
    "        for training_window in training_window_list:\n",
    "\n",
    "            variance_list_sum_mfcf_for_different_clique,return_list_sum_mfcf_for_different_clique=[],[] # result list for this combination of training date, testing date and method\n",
    "            for max_clique_size in max_clique_size_list:\n",
    "\n",
    "                ct_control['max_clique_size'] = max_clique_size\n",
    "                print(ct_control['max_clique_size'])\n",
    "\n",
    "                variance_list_sum_mfcf,return_list_sum_mfcf = mfcf_test(random_date_list,in_sample_return_matrix_list, \n",
    "                                                                    out_sample_return_matrix_list,\n",
    "                                                                    model_input,iteration_range_mfcf,\n",
    "                                                                    ct_control=ct_control,training_window =training_window, \n",
    "                                                                    testing_window=testing_window,given_return=False,in_sample=False,method=method)\n",
    "                variance_list_sum_mfcf_for_different_clique.append(variance_list_sum_mfcf)\n",
    "                return_list_sum_mfcf_for_different_clique.append(return_list_sum_mfcf)\n",
    "                print('=======================',max_clique_size)\n",
    "\n",
    "            sum_var.append(variance_list_sum_mfcf_for_different_clique)\n",
    "            sum_ret.append(return_list_sum_mfcf_for_different_clique)\n",
    "\n",
    "        sum_var = np.array(sum_var)\n",
    "        sum_ret = np.array(sum_ret)\n",
    "\n",
    "        # plotting\n",
    "        colors = plt.cm.viridis(np.linspace(0, 1, len(max_clique_size_list)))\n",
    "        lambda_range = iteration_range_mfcf # for small scale # 100 points\n",
    "        cliuqe_size_list = max_clique_size_list\n",
    "\n",
    "        for training_index in range(len(sum_var)):\n",
    "            variance_list_sum_mfcf_for_different_clique, return_list_sum_mfcf_for_different_clique=sum_var[training_index],sum_ret[training_index]\n",
    "            for i in range(len(variance_list_sum_mfcf_for_different_clique)):\n",
    "                variance_list_sum_ranged_mfcf = np.mean(variance_list_sum_mfcf_for_different_clique[i], axis=0)\n",
    "                return_list_sum_ranged_mfcf = np.mean(return_list_sum_mfcf_for_different_clique[i], axis=0)\n",
    "                sharpe_ratio_sum_ranged_mfcf = [return_list_sum_ranged_mfcf[j]/variance_list_sum_ranged_mfcf[j] for j in range(len(return_list_sum_ranged_mfcf))]\n",
    "                label = 'max clique size=%d'%cliuqe_size_list[i]\n",
    "                plt.plot(lambda_range,return_list_sum_ranged_mfcf,label=label,color=colors[i])\n",
    "            title = 'λ vs var, OUT, training= %s,testing=%d, method=%s,market=nasdaq'% (training_window_list[training_index],testing_window,method)\n",
    "            plt.title(title)\n",
    "            plt.xlabel('lambda')\n",
    "            plt.ylabel('sharpe ratio')\n",
    "            plt.legend()\n",
    "            #plt.savefig(\"%s/%s %s.png\"%(directory_path,title,datetime.now().strftime(\"%Y%m%d_%H%M%S\"))) # You can specify the format by changing the file extension (e.g., .pdf, .jpg, .svg)\n",
    "            plt.show()\n",
    "\n",
    "        if save_result==True:\n",
    "            #make directory\n",
    "            directory_path = 'method=%s,λ vs SR,OUT, testing = %d'%(method,testing_window)\n",
    "            if not os.path.isdir(directory_path):\n",
    "                os.makedirs(directory_path)\n",
    "            # name of file\n",
    "            title = 'λ vs ret, out of sample_training size = %s,testing size=%d,method=%s'% (str(training_window_list),testing_window,method)\n",
    "            # Flatten the 4D array to convert it into a 2D array\n",
    "            flattened_array = sum_var.reshape(-1, sum_var.shape[-1])\n",
    "            # Save the flattened array to a text file\n",
    "            np.savetxt('%s/%s sum_var %s.txt'%(directory_path,title,str(sum_var.shape)), flattened_array)\n",
    "            flattened_array = sum_ret.reshape(-1, sum_ret.shape[-1])\n",
    "            np.savetxt('%s/%s sum_ret %s.txt'%(directory_path,title,str(sum_ret.shape)), flattened_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Different max clique size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.1 random sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting parameter\n",
    "training_window = 30\n",
    "testing_window = 21\n",
    "method_list = 'std' # method option: 'mean','std','ema','std_o','capm',\n",
    "method_list\n",
    "num_iter=100\n",
    "sample_size = 20\n",
    "max_clique_size_list = [2,3,5,7,10,15,20]#,50]\n",
    "#iteration_range_mfcf = np.arange(-0.05,0.05,0.001) # for small scale\n",
    "iteration_range_mfcf = np.arange(-1,3,0.05) # for large scale\n",
    "save_result = False\n",
    "# generate dataset\n",
    "return_rate_matrix,model_input = generate_nasdaq()\n",
    "in_sample_return_matrix_list, out_sample_return_matrix_list, random_date_list = generate_random_list(return_rate_matrix, model_input, training_window_list, testing_window_list, num_iter=num_iter,sample_size=sample_size)\n",
    "\n",
    "ct_control = {\n",
    "'max_clique_size': 2,\n",
    "'min_clique_size': 1,\n",
    "'threshold': 0.00,\n",
    "'coordination_num':np.inf,\n",
    "'drop_sep': False\n",
    "}\n",
    "\n",
    "sum_var = []\n",
    "sum_ret = []\n",
    "\n",
    "variance_list_sum_mfcf_for_different_clique,return_list_sum_mfcf_for_different_clique=[],[]\n",
    "for max_clique_size in max_clique_size_list:\n",
    "    ct_control['max_clique_size'] = max_clique_size\n",
    "    print(ct_control['max_clique_size'])\n",
    "\n",
    "    variance_list_sum_mfcf,return_list_sum_mfcf = mfcf_test(random_date_list,in_sample_return_matrix_list, \n",
    "                                                        out_sample_return_matrix_list,\n",
    "                                                        model_input,iteration_range_mfcf,\n",
    "                                                        ct_control=ct_control,training_window =training_window, \n",
    "                                                        testing_window=testing_window,given_return=False,in_sample=False,method=method)\n",
    "    variance_list_sum_mfcf_for_different_clique.append(variance_list_sum_mfcf)\n",
    "    return_list_sum_mfcf_for_different_clique.append(return_list_sum_mfcf)\n",
    "    print('=======================',max_clique_size)\n",
    "\n",
    "\n",
    "sum_var = np.array(variance_list_sum_mfcf)\n",
    "sum_ret = np.array(return_list_sum_mfcf)\n",
    "\n",
    "colors = plt.cm.viridis(np.linspace(0, 1, len(max_clique_size_list)))\n",
    "#lambda_range = np.arange(-0.05,0.05,0.002)\n",
    "lambda_range = iteration_range_mfcf # for small scale #100 points\n",
    "\n",
    "for i in range(len(variance_list_sum_mfcf_for_different_clique)):\n",
    "    variance_list_sum_ranged_mfcf = np.mean(variance_list_sum_mfcf_for_different_clique[i], axis=0)\n",
    "    return_list_sum_ranged_mfcf = np.mean(return_list_sum_mfcf_for_different_clique[i], axis=0)\n",
    "    sharpe_ratio_sum_ranged_mfcf = [return_list_sum_ranged_mfcf[j]/variance_list_sum_ranged_mfcf[j] for j in range(len(return_list_sum_ranged_mfcf))]\n",
    "    label = 'max clique size=%d'%max_clique_size_list[i]\n",
    "    plt.plot(lambda_range,return_list_sum_ranged_mfcf,label=label,color=colors[i])\n",
    "title = 'λ vs var, OUT, training= %s,testing=%d, method=%s,market=nasdaq'% (training_window_list[tw],testing_window,method)\n",
    "plt.title(title)\n",
    "plt.xlabel('lambda')\n",
    "plt.ylabel('sharpe ratio')\n",
    "plt.legend()\n",
    "#plt.savefig(\"%s/%s %s.png\"%(directory_path,title,datetime.now().strftime(\"%Y%m%d_%H%M%S\"))) # You can specify the format by changing the file extension (e.g., .pdf, .jpg, .svg)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "if save_result==True:\n",
    "    #make directory\n",
    "    directory_path = 'method=%s,λ vs SR,OUT, testing = %d'%(method,testing_window)\n",
    "    if not os.path.isdir(directory_path):\n",
    "        os.makedirs(directory_path)\n",
    "    # name of file\n",
    "    title = 'λ vs ret, out of sample_training size = %s,testing size=%d,method=%s'% (str(training_window_list),testing_window,method)\n",
    "    # Flatten the 4D array to convert it into a 2D array\n",
    "    flattened_array = sum_var.reshape(-1, sum_var.shape[-1])\n",
    "    # Save the flattened array to a text file\n",
    "    np.savetxt('%s/%s sum_var %s.txt'%(directory_path,title,str(sum_var.shape)), flattened_array)\n",
    "    flattened_array = sum_ret.reshape(-1, sum_ret.shape[-1])\n",
    "    np.savetxt('%s/%s sum_ret %s.txt'%(directory_path,title,str(sum_ret.shape)), flattened_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.2 Time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def performance_daily(rd_date, in_sample_return_matrix, \n",
    "                      out_sample_return_matrix, model_input,\n",
    "                        lmda,\n",
    "                        ct_control = None,                 \n",
    "                        in_sample=False,\n",
    "                        method='mean'):\n",
    "\n",
    "    print(rd_date)\n",
    "    in_sample_mean,cov,adj_matrix = generate_cov_mfcf(in_sample_return_matrix, model_input,\n",
    "                                                                    rd_date, training_window,\n",
    "                                                                    ct_control=ct_control,\n",
    "                                                                    method=method)\n",
    "    \n",
    "\n",
    "    mean = np.array(in_sample_mean)\n",
    "    a = np.ones(len(adj_matrix)).T.dot(adj_matrix.dot(np.ones(len(adj_matrix))))\n",
    "    b = np.ones(len(adj_matrix)).T.dot(adj_matrix.dot(mean))\n",
    "    gamma = (1-lmda*b)/a\n",
    "    optmised_weight = adj_matrix.dot(mean*lmda+gamma*np.ones(len(mean)))\n",
    "    normalised_weights = optmised_weight / np.sum(optmised_weight)\n",
    "    weights = np.array(normalised_weights)\n",
    "\n",
    "    if in_sample==True:\n",
    "    # out of sample mean and cov(therefore ret and var)\n",
    "        df = in_sample_return_matrix\n",
    "    else:\n",
    "        df = out_sample_return_matrix\n",
    "\n",
    "    mean =df.mean()*252\n",
    "    cov = df.cov()*252\n",
    "    ret = mean.dot(weights)\n",
    "    vol = np.sqrt(weights.T.dot(cov.dot(weights)))\n",
    "    return ret, vol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# daily_performance ——> input(rd_date, in, out, mi, lmda), output(var,ret)\n",
    "# generate_random_list ——> input(assigned_date, return_m, mi,tw,)\n",
    "#                          output(in_sample_dict, out_of_sample_dict)\n",
    "training_window_list = [30]\n",
    "testing_window_list = [21]\n",
    "num_iter=100\n",
    "return_rate_matrix,model_input = generate_nasdaq() \n",
    "method = 'std'\n",
    "n=100\n",
    "lmda=0.1\n",
    "max_clique_size_list = [2,3,5,7,10,15,20]#,50]\n",
    "random_date_assigned = np.arange(model_input['Index'].min(),model_input['Index'].max(),20)\n",
    "#iteration_range_mfcf = np.arange(-0.05,0.05,0.001) # for small scale\n",
    "iteration_range_mfcf = np.arange(-1,3,0.05) # for large scale\n",
    "\n",
    "averages = {}\n",
    "ct_control = {\n",
    "'max_clique_size': 2,\n",
    "'min_clique_size': 1,\n",
    "'threshold': 0.00,\n",
    "'coordination_num':np.inf,\n",
    "'drop_sep': False\n",
    "}\n",
    "for max_clique_size in max_clique_size_list:\n",
    "    results = {}\n",
    "    ct_control['max_clique_size'] = max_clique_size\n",
    "    print('=======================',max_clique_size)\n",
    "\n",
    "    for _ in range(n): # number of trials\n",
    "        # generate data for this test\n",
    "        in_sample_return_matrix_list, out_sample_return_matrix_list, random_date_list = generate_random_list(return_rate_matrix, model_input, training_window_list, testing_window_list, num_iter=num_iter,sample_size=30,random_date_assigned=random_date_assigned)\n",
    "\n",
    "        for rd_date in random_date_assigned:\n",
    "            if (training_window,rd_date) in in_sample_return_matrix_list:\n",
    "                in_sample_data = in_sample_return_matrix_list[(training_window,rd_date)]\n",
    "                out_sample_data = out_sample_return_matrix_list[(testing_window,rd_date)]\n",
    "                try:\n",
    "                    ret, var = performance_daily(rd_date, in_sample_data, \n",
    "                            out_sample_data, model_input,\n",
    "                                lmda,\n",
    "                                ct_control = ct_control,                 \n",
    "                                in_sample=False,\n",
    "                                method=method)\n",
    "                \n",
    "                    if (training_window,testing_window, rd_date) not in results:\n",
    "                        results[(training_window,testing_window, rd_date)] = {'var': [], 'ret': []}\n",
    "                    results[(training_window,testing_window, rd_date)]['var'].append(var)\n",
    "                    results[(training_window,testing_window, rd_date)]['ret'].append(ret)     \n",
    "                except:\n",
    "                    pass\n",
    "    \n",
    "    for key, values in results.items():\n",
    "        averages[key[2],max_clique_size] = {\n",
    "            'avg_var': sum(values['var']) / n,\n",
    "            'avg_ret': sum(values['ret']) / n\n",
    "        }  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for max_clique_size in max_clique_size_list:\n",
    "    print('=======================',max_clique_size)\n",
    "    ret_result = []\n",
    "    var_result = []\n",
    "    date_list = []\n",
    "    for rd_date in random_date_assigned:\n",
    "        if (rd_date,max_clique_size) in averages:\n",
    "            ret_result.append(averages[(rd_date,max_clique_size)]['avg_ret'])\n",
    "            var_result.append(averages[(rd_date,max_clique_size)]['avg_var'])\n",
    "            date_list.append(rd_date)\n",
    "    sharpe_ratio_result = [ret_result[j]/var_result[j] for j in range(len(ret_result))]\n",
    "\n",
    "    label = 'max clique size=%d'%max_clique_size\n",
    "    plt.plot(date_list,var_result,label=label)\n",
    "\n",
    "\n",
    "title = 'sharpe vs time, OUT, ,market=nasdaq'\n",
    "plt.title(title)\n",
    "plt.xlabel('time')\n",
    "#plt.ylabel('var')\n",
    "plt.ylabel('sharpe ratio')\n",
    "plt.legend()\n",
    "#plt.savefig(\"%s/%s %s.png\"%(directory_path,title,datetime.now().strftime(\"%Y%m%d_%H%M%S\"))) # You can specify the format by changing the file extension (e.g., .pdf, .jpg, .svg)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Max loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_transform_sharpe_ratios_2d(sharpe_ratios_2d):\n",
    "\n",
    "    # Convert input to a numpy array if it is not already\n",
    "    sharpe_ratios_2d = np.array(sharpe_ratios_2d)\n",
    "    \n",
    "    # Apply the log transformation with sign preservation element-wise\n",
    "    transformed_sharpe_ratios_2d = np.sign(sharpe_ratios_2d) * np.log1p(np.abs(sharpe_ratios_2d))\n",
    "    \n",
    "    return transformed_sharpe_ratios_2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_drawdown_det(rd_date, in_sample_return_matrix, \n",
    "                      out_sample_return_matrix, model_input,\n",
    "                        lmda,training_window = 30,\n",
    "                        ct_control = None,                 \n",
    "                        in_sample=False,\n",
    "                        method='mean'):\n",
    "    # define sum up list\n",
    "\n",
    "    print(rd_date)\n",
    "    in_sample_mean,cov,adj_matrix = generate_cov_mfcf(in_sample_return_matrix, model_input,\n",
    "                                                                    rd_date, training_window,\n",
    "                                                                    ct_control=ct_control,\n",
    "                                                                    method=method)\n",
    "    \n",
    "\n",
    "    mean = np.array(in_sample_mean)\n",
    "    a = np.ones(len(adj_matrix)).T.dot(adj_matrix.dot(np.ones(len(adj_matrix))))\n",
    "    b = np.ones(len(adj_matrix)).T.dot(adj_matrix.dot(mean))\n",
    "    #lmda = (mean.mean()-b/a)/(mean.T.dot(adj_matrix.dot(mean))-b**2/a)\n",
    "    #lmda = lambda\n",
    "    gamma = (1-lmda*b)/a\n",
    "    optmised_weight = adj_matrix.dot(mean*lmda+gamma*np.ones(len(mean)))\n",
    "    normalised_weights = optmised_weight / np.sum(optmised_weight)\n",
    "    weights = np.array(normalised_weights)\n",
    "\n",
    "    if in_sample==True:\n",
    "    # out of sample mean and cov(therefore ret and var)\n",
    "        df = in_sample_return_matrix\n",
    "    else:\n",
    "        df = out_sample_return_matrix\n",
    "\n",
    "    max_drawdown = np.inf\n",
    "    # Calculate portfolio returns for each timestamp\n",
    "    portfolio_returns = np.dot(df, weights)\n",
    "    max_drawdown = portfolio_returns.min()\n",
    "    return portfolio_returns\n",
    "    #print(df)\n",
    "    #return max_drawdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_window_list = [30]\n",
    "testing_window_list = [21]\n",
    "num_iter=100\n",
    "return_rate_matrix,model_input = generate_nasdaq()\n",
    "\n",
    "in_sample_return_matrix_list, out_sample_return_matrix_list, random_date_list = generate_random_list(return_rate_matrix, model_input, training_window_list, testing_window_list, num_iter=num_iter,sample_size=20)\n",
    "\n",
    "method = 'std'\n",
    "lmda=0.1\n",
    "max_clique_size_list = [2,5,7,10,15,20]#,50]\n",
    "random_date_assigned = np.arange(model_input['Index'].min(),model_input['Index'].max(),20)\n",
    "#iteration_range_mfcf = np.arange(-0.05,0.05,0.001) # for small scale\n",
    "iteration_range_mfcf = np.arange(-1,3,0.05) # for large scale\n",
    "averages = {}\n",
    "ct_control = {\n",
    "'max_clique_size': 2,\n",
    "'min_clique_size': 1,\n",
    "'threshold': 0.00,\n",
    "'coordination_num':np.inf,\n",
    "'drop_sep': False\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = {}\n",
    "for method in method_list:\n",
    "    for max_clique_size in max_clique_size_list:\n",
    "        results = {}\n",
    "        ct_control['max_clique_size'] = max_clique_size\n",
    "        print('=======================',max_clique_size)\n",
    "\n",
    "        for _ in range(n): # number of trials\n",
    "            # generate data for this test\n",
    "            in_sample_return_matrix_list, out_sample_return_matrix_list, random_date_list = generate_random_list(return_rate_matrix, model_input, training_window_list, testing_window_list, num_iter=num_iter,sample_size=20,random_date_assigned=random_date_assigned)\n",
    "\n",
    "            for rd_date in random_date_assigned:\n",
    "                if (training_window,rd_date) in in_sample_return_matrix_list:\n",
    "                    in_sample_data = in_sample_return_matrix_list[(training_window,rd_date)]\n",
    "                    out_sample_data = out_sample_return_matrix_list[(testing_window,rd_date)]\n",
    "                    #try:\n",
    "                    max_drawdown = max_drawdown_det(rd_date, in_sample_data, \n",
    "                                        out_sample_data, model_input,\n",
    "                                            lmda,\n",
    "                                            ct_control = ct_control,                 \n",
    "                                            in_sample=False,\n",
    "                                            method=method)\n",
    "                \n",
    "                    if (method,training_window,testing_window, rd_date) not in results:\n",
    "                        results[(method,training_window,testing_window, rd_date)] =  []\n",
    "                    results[(method,training_window,testing_window, rd_date)].append(max_drawdown)  \n",
    "                    #except:\n",
    "                    #    pass\n",
    "        raw[(method,max_clique_size)]=results\n",
    "        #for key, values in results.items():\n",
    "        #    averages[key[0],key[2],max_clique_size] = {\n",
    "        #        'avg_max_drawdown': sum(values['max_drawdown']) / n,\n",
    "        #    }  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for max_clique_size in max_clique_size_list:\n",
    "    print('=======================',max_clique_size)\n",
    "    ret_result = []\n",
    "    var_result = []\n",
    "    date_list = []\n",
    "    for rd_date in random_date_assigned:\n",
    "        if (rd_date,max_clique_size) in averages:\n",
    "            ret_result.append(averages[(rd_date,max_clique_size)]['avg_ret'])\n",
    "            var_result.append(averages[(rd_date,max_clique_size)]['avg_var'])\n",
    "            date_list.append(rd_date)\n",
    "    sharpe_ratio_result = [ret_result[j]/var_result[j] for j in range(len(ret_result))]\n",
    "    normalized_sr = log_transform_sharpe_ratios_2d(sharpe_ratio_result)\n",
    "    label = 'max clique size=%d'%max_clique_size\n",
    "    plt.plot(date_list,normalized_sr,label=label)\n",
    "\n",
    "title = 'max loss, sharpe vs time, out, market=nasdaq'\n",
    "plt.title(title)\n",
    "plt.xlabel('time')\n",
    "plt.ylabel('sharpe ratio')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 distribution of weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to plot out the weight\n",
    "def weight_dis(weight,bin=1000,title=None,xrange=None):\n",
    "    # distribution of weights\n",
    "    data = pd.Series(np.array(weight))\n",
    "    if title:\n",
    "        data.plot(kind='hist', bins=bin, alpha=0.7, title=title)\n",
    "    else:\n",
    "        data.plot(kind='hist', bins=bin, alpha=0.7,)# title='distribution of weights(xx data)')\n",
    "    plt.xlabel('Weight')\n",
    "    plt.ylabel('Frequency')\n",
    "    if xrange:\n",
    "        plt.xlim(xrange[0], xrange[1])\n",
    "    plt.show()\n",
    "\n",
    "def weight_test(random_date_list, in_sample_return_matrix_list, \n",
    "                model_input,\n",
    "              ct_control = None, \n",
    "              training_window =1000, \n",
    "            method='mean',lmda = 0.1):\n",
    "    # define sum up list\n",
    "    weights_sum = []\n",
    "    for rd_index in range(len(random_date_list)):\n",
    "        rd_date = random_date_list[rd_index]\n",
    "\n",
    "        in_sample_return_matrix = in_sample_return_matrix_list[(training_window,rd_date)]\n",
    "\n",
    "        in_sample_mean,cov,adj_matrix = generate_cov_mfcf(in_sample_return_matrix, model_input,\n",
    "                                                                     rd_date, training_window,\n",
    "                                                                     ct_control=ct_control,\n",
    "                                                                     method=method)\n",
    "        \n",
    "\n",
    "        mean = np.array(in_sample_mean)\n",
    "        a = np.ones(len(adj_matrix)).T.dot(adj_matrix.dot(np.ones(len(adj_matrix))))\n",
    "        b = np.ones(len(adj_matrix)).T.dot(adj_matrix.dot(mean))\n",
    "        #lmda = (mean.mean()-b/a)/(mean.T.dot(adj_matrix.dot(mean))-b**2/a)\n",
    "        #lmda = i\n",
    "        gamma = (1-lmda*b)/a\n",
    "        optmised_weight = adj_matrix.dot(mean*lmda+gamma*np.ones(len(mean)))\n",
    "        normalised_weights = optmised_weight / np.sum(optmised_weight)\n",
    "        weights = np.array(normalised_weights)\n",
    "        weights_sum.append(weights)\n",
    "  \n",
    "    return weights_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting up parameters\n",
    "ct_control = {\n",
    "'max_clique_size': 2,\n",
    "'min_clique_size': 1,\n",
    "'threshold': 0.00,\n",
    "'coordination_num':np.inf,\n",
    "'drop_sep': False\n",
    "}\n",
    "all_weights = []\n",
    "training_window = 30\n",
    "method = 'mean'\n",
    "lmda = 0.1\n",
    "max_clique_size_list = [2,3,5,7,10,15,20]#,50]\n",
    "sample_size = 20\n",
    "num_iter=100\n",
    "return_rate_matrix,model_input = generate_nasdaq() \n",
    "in_sample_return_matrix_list, out_sample_return_matrix_list, random_date_list = generate_random_list(return_rate_matrix, model_input, training_window_list, testing_window_list, num_iter=num_iter,sample_size=sample_size)\n",
    "weights_sum = []\n",
    "\n",
    "\n",
    "for max_clique_size in max_clique_size_list:\n",
    "    ct_control['max_clique_size'] = max_clique_size\n",
    "    print(ct_control['max_clique_size'])\n",
    "\n",
    "    weight_sum = weight_test(random_date_list, in_sample_return_matrix_list, \n",
    "                model_input,\n",
    "              ct_control = ct_control, \n",
    "              training_window =training_window, \n",
    "            method=method,lmda = lmda)\n",
    "    \n",
    "    all_weights.append(np.array(weight_sum).flatten())\n",
    "\n",
    "\n",
    "# Create box plot\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.boxplot(all_weights, flierprops=dict(marker=''))\n",
    "plt.xlabel('Max Clique size')\n",
    "plt.ylabel('Weights')\n",
    "plt.ylim(-7.5, 7.5)\n",
    "plt.xticks([1, 2, 3, 4,5], ['2', '5', '7', '10', '15'])\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
