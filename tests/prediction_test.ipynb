{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Import libraries and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "import os\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, matthews_corrcoef, f1_score\n",
    "\n",
    "# load model and input\n",
    "parent_dir = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "model_path = os.path.join(parent_dir, 'rf.sav')\n",
    "loaded_model = pickle.load(open(model_path, 'rb'))\n",
    "\n",
    "model_input_data = os.path.join(parent_dir, 'model_input_nasdaq.csv')\n",
    "model_input = pd.read_csv(model_input_data)\n",
    "\n",
    "# select dataset\n",
    "X = model_input[['call_put_ratio_200', # call put raio over the past 200 days\n",
    "                'SQZ', \n",
    "                'MACD',\n",
    "                'vix_fix_gauge', # fear index\n",
    "                'Index', # representing the time series\n",
    "                'Greater_than_MA125', \n",
    "                'Ticker_label', # An arbitary label for ticker, as no categorial/string feature allowed when training\n",
    "                'Close', # closing price\n",
    "                'market_sum' # the sum of the close price for the whole market on the day\n",
    "                                ]]\n",
    "y = [True if model_input['if_profit_21'][i]==1 else False for i in range(len(model_input))]\n",
    "\n",
    "# Split the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9714543573145779\n"
     ]
    }
   ],
   "source": [
    "# accuracy\n",
    "y_pred = loaded_model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matthews Correlation Coefficient: 0.9402894030600676\n"
     ]
    }
   ],
   "source": [
    "# Calculate MCC\n",
    "mcc = matthews_corrcoef(y_test, y_pred)\n",
    "print(f'Matthews Correlation Coefficient: {mcc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.9758592791711251\n"
     ]
    }
   ],
   "source": [
    "# Calculate F1 Score\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "print(f'F1 Score: {f1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Positive Rate: 0.9808509522060752\n"
     ]
    }
   ],
   "source": [
    "# Generate the confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "# Calculate the True Positive Rate (TPR)\n",
    "# cm[1,1] is the number of true positives\n",
    "# cm[1,:].sum() is the number of actual positives (true positives + false negatives)\n",
    "TPR = cm[1, 1] / cm[1, :].sum()\n",
    "print(f'True Positive Rate: {TPR}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendix: Training Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from filterpy.kalman import KalmanFilter\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split,TimeSeriesSplit, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from filterpy.kalman import KalmanFilter\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split,TimeSeriesSplit, cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, make_scorer\n",
    "from sklearn.metrics import confusion_matrix, matthews_corrcoef, f1_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter\n",
    "import os\n",
    "\n",
    "model_input_data = os.path.join(parent_dir, 'model_input_nasdaq.csv')\n",
    "model_input = pd.read_csv(model_input_data)\n",
    "\n",
    "# Select features and target\n",
    "features = ['call_put_ratio_200', # call put raio over the past 200 days\n",
    "                'SQZ', \n",
    "                'MACD',\n",
    "                'vix_fix_gauge', # fear index\n",
    "                'Index', # representing the time series\n",
    "                'Greater_than_MA125', \n",
    "                'Ticker_label', # An arbitary label for ticker, as no categorial/string feature allowed when training\n",
    "                'Close', # closing price\n",
    "                'market_sum' # the sum of the close price for the whole market on the day\n",
    "                                ]\n",
    "target = 'if_profit_21'\n",
    "\n",
    "\n",
    "X = model_input[features]\n",
    "y = [True if model_input['if_profit_21'][i]==1 else False for i in range(len(model_input))]\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(False, 76175), (True, 76175)]\n"
     ]
    }
   ],
   "source": [
    "# fix the data imbalance\n",
    "X_train, y_train = SMOTE().fit_resample(X_train, y_train)\n",
    "print(sorted(Counter(y_train).items())) # verify the balanced data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.5603019363308172\n",
      "Testing Accuracy: 0.5599850620857063\n",
      "Matthews Correlation Coefficient: 0.10581967747224609\n",
      "F1 Score: 0.6123646333104866\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\python\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# LogisticRegression\n",
    "linear_model = LogisticRegression()\n",
    "\n",
    "linear_model.fit(X_train, y_train)\n",
    "\n",
    "# make prediction\n",
    "y_pred = linear_model.predict(X_test)\n",
    "\n",
    "\n",
    "# testing accuracy on training and testing set\n",
    "y_pred_train = linear_model.predict(X_train)\n",
    "y_pred_test = linear_model.predict(X_test)\n",
    "\n",
    "training_accuracy = accuracy_score(y_train, y_pred_train)\n",
    "print(f'Training Accuracy: {training_accuracy}')\n",
    "testing_accuracy = accuracy_score(y_test, y_pred_test)\n",
    "print(f'Testing Accuracy: {testing_accuracy}')\n",
    "\n",
    "# Calculate MCC\n",
    "mcc = matthews_corrcoef(y_test, y_pred)\n",
    "# Calculate F1 Score\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "print(f'Matthews Correlation Coefficient: {mcc}')\n",
    "print(f'F1 Score: {f1}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.5628487036429275\n",
      "Testing Accuracy: 0.5454828369588897\n",
      "Matthews Correlation Coefficient: 0.10132847737977792\n",
      "F1 Score: 0.5735143816615564\n"
     ]
    }
   ],
   "source": [
    "decision_tree_model = DecisionTreeClassifier(class_weight = None, criterion= 'gini', \n",
    "                                            max_depth= 10, max_features= 'sqrt',\n",
    "                                            min_samples_leaf= 1, min_samples_split= 5, splitter= 'random')\n",
    "decision_tree_model.fit(X_train, y_train)\n",
    "\n",
    "# make prediction\n",
    "y_pred = decision_tree_model.predict(X_test)\n",
    "\n",
    "\n",
    "# testing accuracy on training and testing set\n",
    "y_pred_train = decision_tree_model.predict(X_train)\n",
    "y_pred_test = decision_tree_model.predict(X_test)\n",
    "\n",
    "training_accuracy = accuracy_score(y_train, y_pred_train)\n",
    "print(f'Training Accuracy: {training_accuracy}')\n",
    "testing_accuracy = accuracy_score(y_test, y_pred_test)\n",
    "print(f'Testing Accuracy: {testing_accuracy}')\n",
    "\n",
    "# Calculate MCC\n",
    "mcc = matthews_corrcoef(y_test, y_pred)\n",
    "# Calculate F1 Score\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "print(f'Matthews Correlation Coefficient: {mcc}')\n",
    "print(f'F1 Score: {f1}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.9999934361667213\n",
      "Testing Accuracy: 0.8545109389101546\n",
      "Matthews Correlation Coefficient: 0.6991445554932794\n",
      "F1 Score: 0.8768343125115262\n"
     ]
    }
   ],
   "source": [
    "random_forest_model = RandomForestClassifier(criterion= 'gini',\n",
    "                                            max_depth= None,\n",
    "                                            max_features= 'sqrt',\n",
    "                                            min_samples_leaf= 1,\n",
    "                                            min_samples_split= 2,\n",
    "                                            min_weight_fraction_leaf= 0.0,\n",
    "                                            monotonic_cst= None,\n",
    "                                            n_estimators= 100,\n",
    "                                            oob_score= False,)\n",
    "random_forest_model.fit(X_train, y_train)\n",
    "\n",
    "# make prediction\n",
    "y_pred = random_forest_model.predict(X_test)\n",
    "\n",
    "\n",
    "# testing accuracy on training and testing set\n",
    "y_pred_train = random_forest_model.predict(X_train)\n",
    "y_pred_test = random_forest_model.predict(X_test)\n",
    "\n",
    "training_accuracy = accuracy_score(y_train, y_pred_train)\n",
    "print(f'Training Accuracy: {training_accuracy}')\n",
    "testing_accuracy = accuracy_score(y_test, y_pred_test)\n",
    "print(f'Testing Accuracy: {testing_accuracy}')\n",
    "\n",
    "# Calculate MCC\n",
    "mcc = matthews_corrcoef(y_test, y_pred)\n",
    "# Calculate F1 Score\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "print(f'Matthews Correlation Coefficient: {mcc}')\n",
    "print(f'F1 Score: {f1}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.6113160485723662\n",
      "Testing Accuracy: 0.6190831855102231\n",
      "Matthews Correlation Coefficient: 0.21488019887530396\n",
      "F1 Score: 0.6751075011944577\n"
     ]
    }
   ],
   "source": [
    "xgboost_model = XGBClassifier(colsample_bytree=0.8, gamma= 0, learning_rate=0.01, max_depth= 3, n_estimators= 100, \n",
    "                            reg_alpha= 0.1, reg_lambda= 1.5, subsample= 1.0)\n",
    "xgboost_model.fit(X_train, y_train)\n",
    "\n",
    "# make prediction\n",
    "y_pred = xgboost_model.predict(X_test)\n",
    "\n",
    "\n",
    "# testing accuracy on training and testing set\n",
    "y_pred_train = xgboost_model.predict(X_train)\n",
    "y_pred_test = xgboost_model.predict(X_test)\n",
    "\n",
    "training_accuracy = accuracy_score(y_train, y_pred_train)\n",
    "print(f'Training Accuracy: {training_accuracy}')\n",
    "testing_accuracy = accuracy_score(y_test, y_pred_test)\n",
    "print(f'Testing Accuracy: {testing_accuracy}')\n",
    "\n",
    "# Calculate MCC\n",
    "mcc = matthews_corrcoef(y_test, y_pred)\n",
    "# Calculate F1 Score\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "print(f'Matthews Correlation Coefficient: {mcc}')\n",
    "print(f'F1 Score: {f1}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
